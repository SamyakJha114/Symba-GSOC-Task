{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fdd562",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:10.283437Z",
     "iopub.status.busy": "2024-03-30T06:34:10.283080Z",
     "iopub.status.idle": "2024-03-30T06:34:19.072302Z",
     "shell.execute_reply": "2024-03-30T06:34:19.071539Z"
    },
    "papermill": {
     "duration": 8.809613,
     "end_time": "2024-03-30T06:34:19.074583",
     "exception": false,
     "start_time": "2024-03-30T06:34:10.264970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "from sympy import *\n",
    "import pandas as pd\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from dataclasses import dataclass, field, fields\n",
    "from typing import Optional\n",
    "from transformers import LEDForConditionalGeneration,LEDConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262fba59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.106721Z",
     "iopub.status.busy": "2024-03-30T06:34:19.106244Z",
     "iopub.status.idle": "2024-03-30T06:34:19.110407Z",
     "shell.execute_reply": "2024-03-30T06:34:19.109536Z"
    },
    "papermill": {
     "duration": 0.022191,
     "end_time": "2024-03-30T06:34:19.112329",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.090138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#60 ,#113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a8b9b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.144987Z",
     "iopub.status.busy": "2024-03-30T06:34:19.144638Z",
     "iopub.status.idle": "2024-03-30T06:34:19.149615Z",
     "shell.execute_reply": "2024-03-30T06:34:19.148835Z"
    },
    "papermill": {
     "duration": 0.022834,
     "end_time": "2024-03-30T06:34:19.151389",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.128555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i : i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1016cb47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.182431Z",
     "iopub.status.busy": "2024-03-30T06:34:19.182165Z",
     "iopub.status.idle": "2024-03-30T06:34:19.189350Z",
     "shell.execute_reply": "2024-03-30T06:34:19.188583Z"
    },
    "papermill": {
     "duration": 0.024824,
     "end_time": "2024-03-30T06:34:19.191298",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.166474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, vocab_path):\n",
    "        self.vocab_path = vocab_path\n",
    "        self.word2id = {}\n",
    "        self.id2word = {}\n",
    "\n",
    "        with open(vocab_path) as file:\n",
    "            words = map(lambda x: x.rstrip('\\n'), file.readlines())\n",
    "\n",
    "        for (n, word) in enumerate(words):\n",
    "            self.word2id[word] = n\n",
    "            self.id2word[n] = word \n",
    "\n",
    "    def encode(self, lst):\n",
    "        return np.array([[self.word2id[j] for j in i] for i in lst], dtype=np.ushort)\n",
    "\n",
    "    def decode(self, lst):\n",
    "        return [[self.id2word[int(j)] for j in i] for i in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f76be82d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.223365Z",
     "iopub.status.busy": "2024-03-30T06:34:19.223077Z",
     "iopub.status.idle": "2024-03-30T06:34:19.239847Z",
     "shell.execute_reply": "2024-03-30T06:34:19.239140Z"
    },
    "papermill": {
     "duration": 0.034885,
     "end_time": "2024-03-30T06:34:19.241781",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.206896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder_tokeniser(Tokenizer):\n",
    "    def __init__(self,float_precision,mantissa_len,max_exponent,vocab_path,max_len = 10):\n",
    "        super().__init__(vocab_path)\n",
    "        \n",
    "        self.max_len = max_len\n",
    "        self.float_precision = float_precision\n",
    "        self.mantissa_len = mantissa_len\n",
    "        self.max_exponent = max_exponent\n",
    "        self.base = (self.float_precision + 1) // self.mantissa_len\n",
    "        self.max_token = 10 ** self.base\n",
    "        \n",
    "    def pre_tokenize(self, data):\n",
    "        arr = np.array([i.split() for i in data], dtype=np.float32)\n",
    "        permutation = [-1] + [i for i in range(arr.shape[1]-1)]\n",
    "        arr = np.pad(arr[:, permutation], ((0,0), (0, self.max_len - arr.shape[1])), mode=\"constant\", constant_values=[-np.inf])\n",
    "        return arr\n",
    "    \n",
    "    def tokenize(self, data):\n",
    "        out = self.pre_tokenize(data)\n",
    "        out = self.encode_float(out)\n",
    "        out = self.encode(out)\n",
    "        return out\n",
    "        \n",
    "    def encode_float(self,values):\n",
    "        if len(values.shape) == 1:\n",
    "            seq = []\n",
    "            value = values\n",
    "            for val in value:\n",
    "                if val in [-np.inf, np.inf]:\n",
    "                    seq.extend(['<pad>']*3)\n",
    "                    continue\n",
    "                \n",
    "                sign = \"+\" if val >= 0 else \"-\"\n",
    "                m, e = (f\"%.{self.float_precision}e\" % val).split(\"e\")\n",
    "                i, f = m.lstrip(\"-\").split(\".\")\n",
    "                i = i + f\n",
    "                tokens = chunks(i, self.base)\n",
    "                expon = int(e) - self.float_precision\n",
    "                if expon < -self.max_exponent:\n",
    "                    tokens = [\"0\" * self.base] * self.mantissa_len\n",
    "                    expon = int(0)\n",
    "                seq.extend([sign, *[\"N\" + token for token in tokens], \"E\" + str(expon)])\n",
    "            return seq\n",
    "        else:\n",
    "            seqs = [self.encode_float(values[0])]\n",
    "            N = values.shape[0]\n",
    "            for n in range(1, N):\n",
    "                seqs += [self.encode_float(values[n])]\n",
    "        return seqs\n",
    "    def decode_float(self,seq):\n",
    "        decoded_seq = []\n",
    "        for val in chunks(decoded_seq, 2 + self.mantissa_len):\n",
    "            for x in val:\n",
    "                if x[0] not in [\"-\", \"+\", \"E\", \"N\"]:\n",
    "                    return np.nan\n",
    "            try:\n",
    "                sign = 1 if val[0] == \"+\" else -1\n",
    "                mant = \"\"\n",
    "                for x in val[1:-1]:\n",
    "                    mant += x[1:]\n",
    "                mant = int(mant)\n",
    "                exp = int(val[-1][1:])\n",
    "                value = sign * mant * (10 ** exp)\n",
    "                value = float(value)\n",
    "            except Exception:\n",
    "                value = np.nan\n",
    "            decoded_seq.append(value)\n",
    "        return decoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f754c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.273434Z",
     "iopub.status.busy": "2024-03-30T06:34:19.272723Z",
     "iopub.status.idle": "2024-03-30T06:34:19.291212Z",
     "shell.execute_reply": "2024-03-30T06:34:19.290289Z"
    },
    "papermill": {
     "duration": 0.036374,
     "end_time": "2024-03-30T06:34:19.293242",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.256868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_target = pd.read_csv('/kaggle/input/gsoc-symba-task/FeynmanEquations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ae6b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.325444Z",
     "iopub.status.busy": "2024-03-30T06:34:19.325159Z",
     "iopub.status.idle": "2024-03-30T06:34:19.367018Z",
     "shell.execute_reply": "2024-03-30T06:34:19.366109Z"
    },
    "papermill": {
     "duration": 0.060048,
     "end_time": "2024-03-30T06:34:19.368936",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.308888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Number</th>\n",
       "      <th>Output</th>\n",
       "      <th>Formula</th>\n",
       "      <th># variables</th>\n",
       "      <th>v1_name</th>\n",
       "      <th>v1_low</th>\n",
       "      <th>v1_high</th>\n",
       "      <th>v2_name</th>\n",
       "      <th>v2_low</th>\n",
       "      <th>...</th>\n",
       "      <th>v7_high</th>\n",
       "      <th>v8_name</th>\n",
       "      <th>v8_low</th>\n",
       "      <th>v8_high</th>\n",
       "      <th>v9_name</th>\n",
       "      <th>v9_low</th>\n",
       "      <th>v9_high</th>\n",
       "      <th>v10_name</th>\n",
       "      <th>v10_low</th>\n",
       "      <th>v10_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I.6.2a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>f</td>\n",
       "      <td>exp(-theta**2/2)/sqrt(2*pi)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>theta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I.6.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>f</td>\n",
       "      <td>exp(-(theta/sigma)**2/2)/(sqrt(2*pi)*sigma)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>sigma</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>theta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I.6.2b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>f</td>\n",
       "      <td>exp(-((theta-theta1)/sigma)**2/2)/(sqrt(2*pi)*...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>sigma</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>theta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I.8.14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>d</td>\n",
       "      <td>sqrt((x2-x1)**2+(y2-y1)**2)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>x1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>x2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I.9.18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>G*m1*m2/((x2-x1)**2+(y2-y1)**2+(z2-z1)**2)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>m1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>m2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>z1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>z2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename  Number Output  \\\n",
       "0     I.6.2a     1.0      f   \n",
       "1      I.6.2     2.0      f   \n",
       "2     I.6.2b     3.0      f   \n",
       "3     I.8.14     4.0      d   \n",
       "4     I.9.18     5.0      F   \n",
       "..       ...     ...    ...   \n",
       "125      NaN     NaN    NaN   \n",
       "126      NaN     NaN    NaN   \n",
       "127      NaN     NaN    NaN   \n",
       "128      NaN     NaN    NaN   \n",
       "129      NaN     NaN    NaN   \n",
       "\n",
       "                                               Formula  # variables v1_name  \\\n",
       "0                          exp(-theta**2/2)/sqrt(2*pi)          1.0   theta   \n",
       "1          exp(-(theta/sigma)**2/2)/(sqrt(2*pi)*sigma)          2.0   sigma   \n",
       "2    exp(-((theta-theta1)/sigma)**2/2)/(sqrt(2*pi)*...          3.0   sigma   \n",
       "3                          sqrt((x2-x1)**2+(y2-y1)**2)          4.0      x1   \n",
       "4           G*m1*m2/((x2-x1)**2+(y2-y1)**2+(z2-z1)**2)          9.0      m1   \n",
       "..                                                 ...          ...     ...   \n",
       "125                                                NaN          NaN     NaN   \n",
       "126                                                NaN          NaN     NaN   \n",
       "127                                                NaN          NaN     NaN   \n",
       "128                                                NaN          NaN     NaN   \n",
       "129                                                NaN          NaN     NaN   \n",
       "\n",
       "     v1_low  v1_high v2_name  v2_low  ...  v7_high v8_name  v8_low  v8_high  \\\n",
       "0       1.0      3.0     NaN     NaN  ...      NaN     NaN     NaN      NaN   \n",
       "1       1.0      3.0   theta     1.0  ...      NaN     NaN     NaN      NaN   \n",
       "2       1.0      3.0   theta     1.0  ...      NaN     NaN     NaN      NaN   \n",
       "3       1.0      5.0      x2     1.0  ...      NaN     NaN     NaN      NaN   \n",
       "4       1.0      2.0      m2     1.0  ...      2.0      z1     3.0      4.0   \n",
       "..      ...      ...     ...     ...  ...      ...     ...     ...      ...   \n",
       "125     NaN      NaN     NaN     NaN  ...      NaN     NaN     NaN      NaN   \n",
       "126     NaN      NaN     NaN     NaN  ...      NaN     NaN     NaN      NaN   \n",
       "127     NaN      NaN     NaN     NaN  ...      NaN     NaN     NaN      NaN   \n",
       "128     NaN      NaN     NaN     NaN  ...      NaN     NaN     NaN      NaN   \n",
       "129     NaN      NaN     NaN     NaN  ...      NaN     NaN     NaN      NaN   \n",
       "\n",
       "    v9_name  v9_low  v9_high v10_name  v10_low  v10_high  \n",
       "0       NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "1       NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "2       NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "3       NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "4        z2     1.0      2.0      NaN      NaN       NaN  \n",
       "..      ...     ...      ...      ...      ...       ...  \n",
       "125     NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "126     NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "127     NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "128     NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "129     NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "\n",
       "[130 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a18c660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.402046Z",
     "iopub.status.busy": "2024-03-30T06:34:19.401747Z",
     "iopub.status.idle": "2024-03-30T06:34:19.439349Z",
     "shell.execute_reply": "2024-03-30T06:34:19.438431Z"
    },
    "papermill": {
     "duration": 0.05611,
     "end_time": "2024-03-30T06:34:19.441392",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.385282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Number</th>\n",
       "      <th>Output</th>\n",
       "      <th>Formula</th>\n",
       "      <th># variables</th>\n",
       "      <th>v1_name</th>\n",
       "      <th>v1_low</th>\n",
       "      <th>v1_high</th>\n",
       "      <th>v2_name</th>\n",
       "      <th>v2_low</th>\n",
       "      <th>...</th>\n",
       "      <th>v7_high</th>\n",
       "      <th>v8_name</th>\n",
       "      <th>v8_low</th>\n",
       "      <th>v8_high</th>\n",
       "      <th>v9_name</th>\n",
       "      <th>v9_low</th>\n",
       "      <th>v9_high</th>\n",
       "      <th>v10_name</th>\n",
       "      <th>v10_low</th>\n",
       "      <th>v10_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I.6.2a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>f</td>\n",
       "      <td>exp(-theta**2/2)/sqrt(2*pi)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>theta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I.6.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>f</td>\n",
       "      <td>exp(-(theta/sigma)**2/2)/(sqrt(2*pi)*sigma)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>sigma</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>theta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I.6.2b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>f</td>\n",
       "      <td>exp(-((theta-theta1)/sigma)**2/2)/(sqrt(2*pi)*...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>sigma</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>theta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I.8.14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>d</td>\n",
       "      <td>sqrt((x2-x1)**2+(y2-y1)**2)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>x1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>x2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I.9.18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>G*m1*m2/((x2-x1)**2+(y2-y1)**2+(z2-z1)**2)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>m1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>m2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>z1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>z2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>III.15.14</td>\n",
       "      <td>96.0</td>\n",
       "      <td>m</td>\n",
       "      <td>(h/(2*pi))**2/(2*E_n*d**2)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>h</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E_n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>III.15.27</td>\n",
       "      <td>97.0</td>\n",
       "      <td>k</td>\n",
       "      <td>2*pi*alpha/(n*d)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>III.17.37</td>\n",
       "      <td>98.0</td>\n",
       "      <td>f</td>\n",
       "      <td>beta*(1+alpha*cos(theta))</td>\n",
       "      <td>3.0</td>\n",
       "      <td>beta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>III.19.51</td>\n",
       "      <td>99.0</td>\n",
       "      <td>E_n</td>\n",
       "      <td>-m*q**4/(2*(4*pi*epsilon)**2*(h/(2*pi))**2)*(1...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>m</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>III.21.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>j</td>\n",
       "      <td>-rho_c_0*q*A_vec/m</td>\n",
       "      <td>4.0</td>\n",
       "      <td>rho_c_0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename  Number Output  \\\n",
       "0      I.6.2a     1.0      f   \n",
       "1       I.6.2     2.0      f   \n",
       "2      I.6.2b     3.0      f   \n",
       "3      I.8.14     4.0      d   \n",
       "4      I.9.18     5.0      F   \n",
       "..        ...     ...    ...   \n",
       "95  III.15.14    96.0      m   \n",
       "96  III.15.27    97.0      k   \n",
       "97  III.17.37    98.0      f   \n",
       "98  III.19.51    99.0    E_n   \n",
       "99  III.21.20   100.0      j   \n",
       "\n",
       "                                              Formula  # variables  v1_name  \\\n",
       "0                         exp(-theta**2/2)/sqrt(2*pi)          1.0    theta   \n",
       "1         exp(-(theta/sigma)**2/2)/(sqrt(2*pi)*sigma)          2.0    sigma   \n",
       "2   exp(-((theta-theta1)/sigma)**2/2)/(sqrt(2*pi)*...          3.0    sigma   \n",
       "3                         sqrt((x2-x1)**2+(y2-y1)**2)          4.0       x1   \n",
       "4          G*m1*m2/((x2-x1)**2+(y2-y1)**2+(z2-z1)**2)          9.0       m1   \n",
       "..                                                ...          ...      ...   \n",
       "95                         (h/(2*pi))**2/(2*E_n*d**2)          3.0        h   \n",
       "96                                   2*pi*alpha/(n*d)          3.0    alpha   \n",
       "97                          beta*(1+alpha*cos(theta))          3.0     beta   \n",
       "98  -m*q**4/(2*(4*pi*epsilon)**2*(h/(2*pi))**2)*(1...          4.0        m   \n",
       "99                                 -rho_c_0*q*A_vec/m          4.0  rho_c_0   \n",
       "\n",
       "    v1_low  v1_high v2_name  v2_low  ...  v7_high v8_name  v8_low  v8_high  \\\n",
       "0      1.0      3.0     NaN     NaN  ...      NaN     NaN     NaN      NaN   \n",
       "1      1.0      3.0   theta     1.0  ...      NaN     NaN     NaN      NaN   \n",
       "2      1.0      3.0   theta     1.0  ...      NaN     NaN     NaN      NaN   \n",
       "3      1.0      5.0      x2     1.0  ...      NaN     NaN     NaN      NaN   \n",
       "4      1.0      2.0      m2     1.0  ...      2.0      z1     3.0      4.0   \n",
       "..     ...      ...     ...     ...  ...      ...     ...     ...      ...   \n",
       "95     1.0      5.0     E_n     1.0  ...      NaN     NaN     NaN      NaN   \n",
       "96     1.0      5.0       n     1.0  ...      NaN     NaN     NaN      NaN   \n",
       "97     1.0      5.0   alpha     1.0  ...      NaN     NaN     NaN      NaN   \n",
       "98     1.0      5.0       q     1.0  ...      NaN     NaN     NaN      NaN   \n",
       "99     1.0      5.0       q     1.0  ...      NaN     NaN     NaN      NaN   \n",
       "\n",
       "   v9_name  v9_low  v9_high v10_name  v10_low  v10_high  \n",
       "0      NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "1      NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "2      NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "3      NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "4       z2     1.0      2.0      NaN      NaN       NaN  \n",
       "..     ...     ...      ...      ...      ...       ...  \n",
       "95     NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "96     NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "97     NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "98     NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "99     NaN     NaN      NaN      NaN      NaN       NaN  \n",
       "\n",
       "[100 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = df_target.dropna(subset=['Filename'])\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3485ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.476629Z",
     "iopub.status.busy": "2024-03-30T06:34:19.475798Z",
     "iopub.status.idle": "2024-03-30T06:34:19.484021Z",
     "shell.execute_reply": "2024-03-30T06:34:19.483190Z"
    },
    "papermill": {
     "duration": 0.028111,
     "end_time": "2024-03-30T06:34:19.486367",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.458256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_target.loc[82, '# variables'] = 3\n",
    "df_target.loc[18,'Filename'] = 'I.15.10'\n",
    "df_target.loc[49,'Filename'] = 'I.48.20'\n",
    "df_target.loc[61,'Filename'] = 'II.11.7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84f8aba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.520456Z",
     "iopub.status.busy": "2024-03-30T06:34:19.520216Z",
     "iopub.status.idle": "2024-03-30T06:34:19.524106Z",
     "shell.execute_reply": "2024-03-30T06:34:19.523266Z"
    },
    "papermill": {
     "duration": 0.022919,
     "end_time": "2024-03-30T06:34:19.525993",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.503074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "used_variables = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8502b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.559507Z",
     "iopub.status.busy": "2024-03-30T06:34:19.559233Z",
     "iopub.status.idle": "2024-03-30T06:34:19.604037Z",
     "shell.execute_reply": "2024-03-30T06:34:19.603319Z"
    },
    "papermill": {
     "duration": 0.063751,
     "end_time": "2024-03-30T06:34:19.605911",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.542160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(df_target)):\n",
    "    for j in range(0,int(df_target.iloc[i]['# variables'])):\n",
    "        used_variables.add(df_target.iloc[i][f'v{j+1}_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975653a5",
   "metadata": {
    "papermill": {
     "duration": 0.016272,
     "end_time": "2024-03-30T06:34:19.639011",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.622739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04fc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):  \n",
    "    variables.append(f'v{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efb79d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.676752Z",
     "iopub.status.busy": "2024-03-30T06:34:19.675783Z",
     "iopub.status.idle": "2024-03-30T06:34:19.693478Z",
     "shell.execute_reply": "2024-03-30T06:34:19.692612Z"
    },
    "papermill": {
     "duration": 0.038449,
     "end_time": "2024-03-30T06:34:19.695389",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.656940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "operators = {\n",
    "    # Elementary functions\n",
    "    sp.Add: 'add',\n",
    "    sp.Mul: 'mul',\n",
    "    sp.Pow: 'pow',\n",
    "    sp.exp: 'exp',\n",
    "    sp.log: 'ln',\n",
    "    sp.Abs: 'abs',\n",
    "    sp.sign: 'sign',\n",
    "    # Trigonometric Functions\n",
    "    sp.sin: 'sin',\n",
    "    sp.cos: 'cos',\n",
    "    sp.tan: 'tan',\n",
    "    sp.cot: 'cot',\n",
    "    sp.sec: 'sec',\n",
    "    sp.csc: 'csc',\n",
    "    # Trigonometric Inverses\n",
    "    sp.asin: 'asin',\n",
    "    sp.acos: 'acos',\n",
    "    sp.atan: 'atan',\n",
    "    sp.acot: 'acot',\n",
    "    sp.asec: 'asec',\n",
    "    sp.acsc: 'acsc',\n",
    "    # Hyperbolic Functions\n",
    "    sp.sinh: 'sinh',\n",
    "    sp.cosh: 'cosh',\n",
    "    sp.tanh: 'tanh',\n",
    "    sp.coth: 'coth',\n",
    "    sp.sech: 'sech',\n",
    "    sp.csch: 'csch',\n",
    "    # Hyperbolic Inverses\n",
    "    sp.asinh: 'asinh',\n",
    "    sp.acosh: 'acosh',\n",
    "    sp.atanh: 'atanh',\n",
    "    sp.acoth: 'acoth',\n",
    "    sp.asech: 'asech',\n",
    "    sp.acsch: 'acsch',\n",
    "    # Derivative\n",
    "    sp.Derivative: 'derivative',\n",
    "}\n",
    "\n",
    "operators_inv = {operators[key]: key for key in operators}\n",
    "operators_inv[\"mul(\"] = sp.Mul\n",
    "operators_inv[\"add(\"] = sp.Add\n",
    "\n",
    "operators_nargs = {\n",
    "    # Elementary functions\n",
    "    'mul(': -1,\n",
    "    'add(': -1,\n",
    "    'add': 2,\n",
    "    'sub': 2,\n",
    "    'mul': 2,\n",
    "    'div': 2,\n",
    "    'pow': 2,\n",
    "    'rac': 2,\n",
    "    'inv': 1,\n",
    "    'pow2': 1,\n",
    "    'pow3': 1,\n",
    "    'pow4': 1,\n",
    "    'pow5': 1,\n",
    "    'sqrt': 1,\n",
    "    'exp': 1,\n",
    "    'ln': 1,\n",
    "    'abs': 1,\n",
    "    'sign': 1,\n",
    "    # Trigonometric Functions\n",
    "    'sin': 1,\n",
    "    'cos': 1,\n",
    "    'tan': 1,\n",
    "    'cot': 1,\n",
    "    'sec': 1,\n",
    "    'csc': 1,\n",
    "    # Trigonometric Inverses\n",
    "    'asin': 1,\n",
    "    'acos': 1,\n",
    "    'atan': 1,\n",
    "    'acot': 1,\n",
    "    'asec': 1,\n",
    "    'acsc': 1,\n",
    "    # Hyperbolic Functions\n",
    "    'sinh': 1,\n",
    "    'cosh': 1,\n",
    "    'tanh': 1,\n",
    "    'coth': 1,\n",
    "    'sech': 1,\n",
    "    'csch': 1,\n",
    "    # Hyperbolic Inverses\n",
    "    'asinh': 1,\n",
    "    'acosh': 1,\n",
    "    'atanh': 1,\n",
    "    'acoth': 1,\n",
    "    'asech': 1,\n",
    "    'acsch': 1,\n",
    "    # Derivative\n",
    "    'derivative': 2,\n",
    "    # custom functions\n",
    "    'f': 1,\n",
    "    'g': 2,\n",
    "    'h': 3,\n",
    "}\n",
    "\n",
    "masses_strings = [\n",
    "        \"m_e\",\n",
    "        \"m_u\",\n",
    "        \"m_d\",\n",
    "        \"m_s\",\n",
    "        \"m_c\",\n",
    "        \"m_b\",\n",
    "        \"m_t\",\n",
    "        ]\n",
    "\n",
    "masses = [sp.Symbol(x) for x in masses_strings]\n",
    "\n",
    "# these will be converted to the numbers format in `format_number`\n",
    "integers_types = [\n",
    "        sp.core.numbers.Integer,\n",
    "        sp.core.numbers.One,\n",
    "        sp.core.numbers.NegativeOne,\n",
    "        sp.core.numbers.Zero,\n",
    "        ]\n",
    "\n",
    "numbers_types = integers_types + [sp.core.numbers.Rational,\n",
    "        sp.core.numbers.Half, sp.core.numbers.Exp1, sp.core.numbers.Pi, \"<class 'sympy.core.numbers.Pi'>\",\n",
    "        sp.core.numbers.ImaginaryUnit]\n",
    "\n",
    "# don't continue evaluating at these, but stop\n",
    "atoms = [\n",
    "        str,\n",
    "        sp.core.symbol.Symbol,\n",
    "        sp.core.numbers.Exp1,\n",
    "        sp.core.numbers.Pi,\n",
    "        \"<class 'sympy.core.numbers.Pi'>\",\n",
    "        ] + numbers_types\n",
    "\n",
    "\n",
    "Inverse_trig = {\n",
    "    'arcsin': 'asin',\n",
    "    'arccos': 'acos',\n",
    "    'arctan': 'atan',\n",
    "    'arccot': 'acot',\n",
    "    'arcsec': 'asec',\n",
    "    'arccsc': 'acsc',\n",
    "    'arcsinh': 'asinh',\n",
    "    'arccosh': 'acosh',\n",
    "    'arctanh': 'atanh',\n",
    "    'arccoth': 'acoth',\n",
    "    'arcsech': 'asech',\n",
    "    'arccsch': 'acsch',         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dc6ad6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.730537Z",
     "iopub.status.busy": "2024-03-30T06:34:19.730209Z",
     "iopub.status.idle": "2024-03-30T06:34:19.735595Z",
     "shell.execute_reply": "2024-03-30T06:34:19.734656Z"
    },
    "papermill": {
     "duration": 0.025055,
     "end_time": "2024-03-30T06:34:19.737582",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.712527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sympy_expression(formula):\n",
    "    # create a map of variables\n",
    "    variables_map = {key : sp.Symbol(key) for key in variables}\n",
    "\n",
    "    for a in Inverse_trig.keys():\n",
    "        formula = re.sub(a,Inverse_trig[a],formula)\n",
    "\n",
    "    # Convert to sympy expression\n",
    "    return sp.sympify(formula, locals=variables_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13913b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.776683Z",
     "iopub.status.busy": "2024-03-30T06:34:19.776197Z",
     "iopub.status.idle": "2024-03-30T06:34:19.785434Z",
     "shell.execute_reply": "2024-03-30T06:34:19.783329Z"
    },
    "papermill": {
     "duration": 0.034191,
     "end_time": "2024-03-30T06:34:19.788273",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.754082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten(l, ltypes=(list, tuple)):\n",
    "    \"\"\"\n",
    "    flatten a python list\n",
    "    from http://rightfootin.blogspot.com/2006/09/more-on-python-flatten.html\n",
    "    \"\"\"\n",
    "    ltype = type(l)\n",
    "    l = list(l)\n",
    "    i = 0\n",
    "    while i < len(l):\n",
    "        while isinstance(l[i], ltypes):\n",
    "            if not l[i]:\n",
    "                l.pop(i)\n",
    "                i -= 1\n",
    "                break\n",
    "            else:\n",
    "                l[i:i + 1] = l[i]\n",
    "        i += 1\n",
    "    return ltype(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36946687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.839380Z",
     "iopub.status.busy": "2024-03-30T06:34:19.838932Z",
     "iopub.status.idle": "2024-03-30T06:34:19.871934Z",
     "shell.execute_reply": "2024-03-30T06:34:19.870929Z"
    },
    "papermill": {
     "duration": 0.059779,
     "end_time": "2024-03-30T06:34:19.874126",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.814347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sympy_to_prefix(expression):\n",
    "    \"\"\"\n",
    "    Recursively go from a sympy expression to a prefix notation.\n",
    "    Returns a flat list of tokens.\n",
    "    \"\"\"\n",
    "    return flatten(sympy_to_prefix_rec(expression, []))\n",
    "\n",
    "def sympy_to_prefix_rec(expression, ret):\n",
    "    \"\"\"\n",
    "    Recursively go from a sympy expression to a prefix notation.\n",
    "    The operators all get converted to their names in the array `operators`.\n",
    "    Returns a nested list, where the nesting basically stands for parentheses.\n",
    "    Since in prefix notation with a fixed number of arguments for each function (given in `operators_nargs`),\n",
    "    parentheses are not needed, we can flatten the list later.\n",
    "    \"\"\"\n",
    "    if expression in [sp.core.numbers.Pi, sp.core.numbers.ImaginaryUnit]:\n",
    "        f = expression\n",
    "    else:\n",
    "        f = expression.func\n",
    "    if f in atoms:\n",
    "        if type(expression) in numbers_types:\n",
    "            return ret + format_number(expression)\n",
    "        return ret+[str(expression)]\n",
    "    f_str = operators[f]\n",
    "    f_nargs = operators_nargs[f_str]\n",
    "    args = expression.args\n",
    "    if len(args) == 1 & f_nargs == 1:\n",
    "        ret = ret + [f_str]\n",
    "        return sympy_to_prefix_rec(args[0], ret)\n",
    "    if len(args) == 2:\n",
    "        ret = ret + [f_str, sympy_to_prefix_rec(args[0], []), sympy_to_prefix_rec(args[1], [])]\n",
    "    if len(args) > 2:\n",
    "        args = list(map(lambda x: sympy_to_prefix_rec(x, []), args))\n",
    "        ret = ret + repeat_operator_until_correct_binary(f_str, args)\n",
    "    return ret\n",
    "def repeat_operator_until_correct_binary(op, args, ret=[]):\n",
    "    \"\"\"\n",
    "    sympy is not strict enough with the number of arguments.\n",
    "    E.g. multiply takes a variable number of arguments, but for\n",
    "    prefix notation it needs to ALWAYS have exactly 2 arguments\n",
    "\n",
    "    This function is only for binary operators.\n",
    "\n",
    "    Here I choose the convention as follows:\n",
    "        1 + 2 + 3 --> + 1 + 2 3\n",
    "\n",
    "    This is the same convention as in https://arxiv.org/pdf/1912.01412.pdf\n",
    "    on page 15.\n",
    "\n",
    "    input:\n",
    "        op: in string form as in the list `operators`\n",
    "        args: [arg1, arg2, ...] arguments of the operator, e.c. [1, 2, x**2,\n",
    "                ...]. They can have other things to be evaluated in them\n",
    "        ret: the list you already have. Usually []. Watch out, I think one has to explicitely give [],\n",
    "            otherwise somehow the default value gets mutated, which I find a strange python behavior.\n",
    "    \"\"\"\n",
    "\n",
    "    is_binary = operators_nargs[op] == 2\n",
    "    assert is_binary, \"repeat_operator_until_correct_binary only takes binary operators\"\n",
    "\n",
    "    if len(args) == 0:\n",
    "        return ret\n",
    "    elif len(ret) == 0:\n",
    "        ret = [op] + args[-2:]\n",
    "        args = args[:-2]\n",
    "    else:\n",
    "        ret = [op] + args[-1:] + ret\n",
    "        args = args[:-1]\n",
    "\n",
    "    return repeat_operator_until_correct_binary(op, args, ret)\n",
    "\n",
    "def format_number(number):\n",
    "    if type(number) in integers_types:\n",
    "        return format_integer(number)\n",
    "    elif type(number) == sp.core.numbers.Rational:\n",
    "        return format_rational(number)\n",
    "    elif type(number) == sp.core.numbers.Half:\n",
    "        return format_half()\n",
    "    elif type(number) == sp.core.numbers.Exp1:\n",
    "        return format_exp1()\n",
    "    elif type(number) == sp.core.numbers.Pi:\n",
    "        return format_pi()\n",
    "    elif type(number) == sp.core.numbers.ImaginaryUnit:\n",
    "        return format_imaginary_unit()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "def format_exp1():\n",
    "    return ['E']\n",
    "\n",
    "def format_pi():\n",
    "    return ['pi']\n",
    "\n",
    "def format_imaginary_unit():\n",
    "    return ['I']\n",
    "\n",
    "def format_half():\n",
    "    \"\"\"\n",
    "    for some reason in sympy 1/2 is its own object and not a rational.\n",
    "    This function formats it correctly like `format_rational`\n",
    "    \"\"\"\n",
    "    return ['mul'] + ['s+', '1'] + ['pow'] + ['s+', '2'] + [\"s-\", \"1\"]\n",
    "\n",
    "def format_rational(number):\n",
    "    # for some reason number.p is a string\n",
    "    p = sp.sympify(number.p)\n",
    "    q = sp.sympify(number.q)\n",
    "    return ['mul'] + format_integer(p) + ['pow'] + format_integer(q) + ['s-', '1']\n",
    "\n",
    "def format_integer(integer):\n",
    "    \"\"\"take a sympy integer and format it as in\n",
    "    https://arxiv.org/pdf/1912.01412.pdf\n",
    "\n",
    "    input:\n",
    "        integer: a `sympy.Integer` object, e.g. `sympy.Integer(-1)`\n",
    "\n",
    "    output:\n",
    "        [sign_token, digit0, digit1, ...]\n",
    "        where sign_token is 's+' or 's-'\n",
    "\n",
    "    Example:\n",
    "        format_integer(sympy.Integer(-123))\n",
    "        >> ['s-', '1', '2', '3']\n",
    "\n",
    "    Implementation notes:\n",
    "    Somehow Integer inherits from Rational in Sympy and a rational is p/q,\n",
    "    so integer.p is used to extract the number.\n",
    "    \"\"\"\n",
    "    # plus_sign = \"s+\"\n",
    "    plus_sign = \"s+\"\n",
    "    minus_sign = \"s-\"\n",
    "    abs_num = abs(integer.p)\n",
    "    is_neg = integer.could_extract_minus_sign()\n",
    "    digits = list(str(abs_num))\n",
    "    # digits = [str(abs_num)]\n",
    "\n",
    "    if is_neg:\n",
    "        ret = [minus_sign] + digits\n",
    "    else:\n",
    "        ret = [plus_sign] + digits\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61ad8ee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.910122Z",
     "iopub.status.busy": "2024-03-30T06:34:19.909130Z",
     "iopub.status.idle": "2024-03-30T06:34:19.914019Z",
     "shell.execute_reply": "2024-03-30T06:34:19.913147Z"
    },
    "papermill": {
     "duration": 0.025149,
     "end_time": "2024-03-30T06:34:19.916342",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.891193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_if_str(x):\n",
    "    if isinstance(x, str):\n",
    "        return sp.parsing.parse_expr(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cda68c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:19.961708Z",
     "iopub.status.busy": "2024-03-30T06:34:19.961348Z",
     "iopub.status.idle": "2024-03-30T06:34:19.969486Z",
     "shell.execute_reply": "2024-03-30T06:34:19.968579Z"
    },
    "papermill": {
     "duration": 0.030954,
     "end_time": "2024-03-30T06:34:19.971482",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.940528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rightmost_string_pos(expr_arr, pos=-1):\n",
    "    if isinstance(expr_arr[pos], str):\n",
    "        return len(expr_arr)+pos\n",
    "    else:\n",
    "        return rightmost_string_pos(expr_arr, pos-1)\n",
    "\n",
    "\n",
    "def rightmost_operand_pos(expr, pos=-1):\n",
    "    operators = list(operators_inv.keys()) + [\"s+\", \"s-\"] + list(variables)\n",
    "    if expr[pos] in operators:\n",
    "        return len(expr) + pos\n",
    "    else:\n",
    "        return rightmost_operand_pos(expr, pos-1)\n",
    "\n",
    "def unformat_integer(arr):\n",
    "    \"\"\"\n",
    "    inverse of the function format_integer.\n",
    "\n",
    "    input:\n",
    "        arr: array of strings just as the output of format_integer. E.g. [\"s+\", \"4\", \"2\"]\n",
    "\n",
    "    output:\n",
    "        the correspinding sympy integer, e.g. sympy.Integer(42) in the above example.\n",
    "\n",
    "    The sign tokens are \"s+\" for positive integers and \"s-\" for negative. 0 comes with \"s+\", but does not matter.\n",
    "\n",
    "    \"\"\"\n",
    "    sign_token = arr[0]\n",
    "    ret = \"-\" if sign_token == \"s-\" else \"\"\n",
    "    for s in arr[1:]:\n",
    "        ret += str(s)\n",
    "\n",
    "    return sp.parsing.parse_expr(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72c87606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:20.018731Z",
     "iopub.status.busy": "2024-03-30T06:34:20.018057Z",
     "iopub.status.idle": "2024-03-30T06:34:20.028579Z",
     "shell.execute_reply": "2024-03-30T06:34:20.027645Z"
    },
    "papermill": {
     "duration": 0.037122,
     "end_time": "2024-03-30T06:34:20.030658",
     "exception": false,
     "start_time": "2024-03-30T06:34:19.993536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prefix_to_sympy(expr_arr):\n",
    "    if len(expr_arr) == 1:\n",
    "        return parse_if_str(expr_arr[0])\n",
    "    op_pos = rightmost_operand_pos(expr_arr)\n",
    "    if (op_pos == -1) | (op_pos == len(expr_arr)):\n",
    "        print(\"something went wrong, operator should not be at end of array\")\n",
    "    op = expr_arr[op_pos]\n",
    "    if op in operators_inv.keys():\n",
    "        num_args = operators_nargs[op]\n",
    "        op = operators_inv[op]\n",
    "        args = expr_arr[op_pos+1:op_pos+num_args+1]\n",
    "        args = [parse_if_str(a) for a in args]\n",
    "        func = op(*args)\n",
    "        expr = expr_arr[0:op_pos] + [func] + expr_arr[op_pos+num_args+1:]\n",
    "        return prefix_to_sympy(expr)\n",
    "\n",
    "    elif (op == 's+') | (op == \"s-\"):\n",
    "        # int_end_pos = rightmost_int_pos(expr_arr)\n",
    "        string_end_pos = rightmost_string_pos(expr_arr)\n",
    "        integer = unformat_integer(expr_arr[op_pos:string_end_pos+1])\n",
    "        expr_arr_new = expr_arr[0:op_pos] + [integer] + expr_arr[string_end_pos+1:]\n",
    "        return prefix_to_sympy(expr_arr_new)\n",
    "    elif op in list(variables):\n",
    "        op = sp.sympify(op)\n",
    "        expr_arr_new = expr_arr[0:op_pos] + [op] + expr_arr[op_pos+1:]\n",
    "#         sp.sympify(op)\n",
    "        return prefix_to_sympy(expr_arr_new)\n",
    "\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ecfcab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:20.066394Z",
     "iopub.status.busy": "2024-03-30T06:34:20.065586Z",
     "iopub.status.idle": "2024-03-30T06:34:20.584317Z",
     "shell.execute_reply": "2024-03-30T06:34:20.583413Z"
    },
    "papermill": {
     "duration": 0.539417,
     "end_time": "2024-03-30T06:34:20.586955",
     "exception": false,
     "start_time": "2024-03-30T06:34:20.047538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix_lists = []\n",
    "for i in range(0,len(df_target)):\n",
    "    x = sympy_expression(df_target['Formula'][i])\n",
    "    prefix_lists.append(sympy_to_prefix(x))\n",
    "df_target = df_target.assign(Prefix_lists=prefix_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bca10",
   "metadata": {
    "papermill": {
     "duration": 0.066653,
     "end_time": "2024-03-30T06:34:20.674452",
     "exception": false,
     "start_time": "2024-03-30T06:34:20.607799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f25d8577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:20.710176Z",
     "iopub.status.busy": "2024-03-30T06:34:20.709283Z",
     "iopub.status.idle": "2024-03-30T06:34:20.719971Z",
     "shell.execute_reply": "2024-03-30T06:34:20.719003Z"
    },
    "papermill": {
     "duration": 0.031061,
     "end_time": "2024-03-30T06:34:20.722046",
     "exception": false,
     "start_time": "2024-03-30T06:34:20.690985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderTokenizer(Tokenizer):\n",
    "    def __init__(self, vocab_path):\n",
    "        super().__init__(vocab_path)\n",
    "\n",
    "    def equation_encoder(self, data):\n",
    "        return [sympy_to_prefix(expr) for expr in data]\n",
    "    \n",
    "    def equation_decoder(self, data):\n",
    "        return [prefix_to_sympy(lst) for lst in data]\n",
    "\n",
    "    def pre_tokenize(self, data):\n",
    "        return data\n",
    "    \n",
    "    def tokenize(self, data):\n",
    "        out = self.pre_tokenize(data)\n",
    "        out = self.equation_encoder(out)\n",
    "        out = [['<bos>'] + i + ['<eos>'] for i in out]\n",
    "        out = self.encode(out)\n",
    "        return out\n",
    "    \n",
    "    def reverse_tokenize(self, data):\n",
    "#         data_lst = []\n",
    "#         for i in range(0,int((data).shape[0])):\n",
    "#             data_lst.append(int(data[i].to('cpu')))\n",
    "        out = self.decode((data))\n",
    "#         out = self.equation_decoder(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed7710a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:20.756786Z",
     "iopub.status.busy": "2024-03-30T06:34:20.756377Z",
     "iopub.status.idle": "2024-03-30T06:34:20.761192Z",
     "shell.execute_reply": "2024-03-30T06:34:20.760281Z"
    },
    "papermill": {
     "duration": 0.024904,
     "end_time": "2024-03-30T06:34:20.763495",
     "exception": false,
     "start_time": "2024-03-30T06:34:20.738591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '/kaggle/input/gsoc-symba-task/Feynman_with_units/Feynman_with_units/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98828166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:20.802572Z",
     "iopub.status.busy": "2024-03-30T06:34:20.802145Z",
     "iopub.status.idle": "2024-03-30T06:34:20.827943Z",
     "shell.execute_reply": "2024-03-30T06:34:20.827081Z"
    },
    "papermill": {
     "duration": 0.046153,
     "end_time": "2024-03-30T06:34:20.829788",
     "exception": false,
     "start_time": "2024-03-30T06:34:20.783635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "\n",
    "def prepare_dataset(config):\n",
    "\n",
    "    input_max_len = config.input_max_len\n",
    "    df = pd.read_csv(config.df_path)\n",
    "\n",
    "    encoder_tokenizer = Encoder_tokeniser(2,1,100,config.encoder_vocab)\n",
    "    decoder_tokenizer = DecoderTokenizer(config.decoder_vocab)\n",
    "\n",
    "    train_df = {\n",
    "        \"Filename\":[],\n",
    "        \"data_num\":[], \n",
    "        \"number\":[]\n",
    "        }\n",
    "    \n",
    "    for (index, row) in tqdm(df.iterrows()):\n",
    "        with open(INPUT_DIR + row['Filename']) as file:\n",
    "            data = file.readlines()\n",
    "        X = encoder_tokenizer.tokenize(data)\n",
    "\n",
    "        n_splits = X.shape[0] // input_max_len\n",
    "        X = X[:n_splits*input_max_len]\n",
    "        x_chunks = np.split(X, n_splits)\n",
    "\n",
    "        sub_dir = os.path.join(config.output_dir, row[\"Filename\"])\n",
    "        os.makedirs(sub_dir, exist_ok=True)\n",
    "        \n",
    "        for (index, x) in enumerate(x_chunks):\n",
    "            np.save(os.path.join(sub_dir, f\"{index}.npy\"), x)\n",
    "\n",
    "        train_df[\"filename\"].extend([row[\"Filename\"]]*n_splits)\n",
    "        train_df[\"data_num\"].extend([i for i in range(n_splits)])\n",
    "        train_df[\"number\"].extend([row[\"Number\"] for i in range(n_splits)])\n",
    "\n",
    "    train_df = pd.DataFrame(train_df)\n",
    "    \n",
    "    prefix_equations = np.zeros((100, 256)).astype(np.int32)\n",
    "    for (index, row) in df.iterrows():\n",
    "        prefix = eval(row[\"Prefix_lists\"])\n",
    "        prefix = [\"<bos>\"] + prefix + [\"<eos>\"]\n",
    "        y = decoder_tokenizer.encode([prefix])[0]\n",
    "        y = np.pad(y, (0, 256 - len(y)))\n",
    "        prefix_equations[int(row[\"Number\"])-1, :] = y\n",
    "\n",
    "    path = os.path.join(config.output_dir, \"prefix_equations.npy\")\n",
    "    np.save(path, prefix_equations)\n",
    "\n",
    "    return train_df\n",
    "\n",
    "class FeynmanDataset(Dataset):\n",
    "    def __init__(self, df, dataset_dir):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.prefix_equations = np.load(os.path.join(dataset_dir, \"prefix_equations.npy\"))\n",
    "        # prefix_equations = []\n",
    "\n",
    "        prefix_equations = []\n",
    "        for prefix in self.prefix_equations:\n",
    "            prefix_equations.append(np.trim_zeros(prefix))\n",
    "\n",
    "        self.prefix_equations = prefix_equations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = os.path.join(os.path.join(self.dataset_dir, row['Filename']), f\"{row['data_num']}.npy\")\n",
    "        x = np.load(path).astype(np.int32)\n",
    "\n",
    "        path = os.path.join(self.dataset_dir, f\"{row['Filename']}.npy\")\n",
    "        y = self.prefix_equations[row['number'] - 1]\n",
    "\n",
    "        return (torch.Tensor(x).long(), torch.Tensor(y).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0715c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:20.865709Z",
     "iopub.status.busy": "2024-03-30T06:34:20.864898Z",
     "iopub.status.idle": "2024-03-30T06:34:20.876145Z",
     "shell.execute_reply": "2024-03-30T06:34:20.875290Z"
    },
    "papermill": {
     "duration": 0.03162,
     "end_time": "2024-03-30T06:34:20.878155",
     "exception": false,
     "start_time": "2024-03-30T06:34:20.846535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_datasets(df, input_df, dataset_dir):\n",
    "    train_df, test_df = train_test_split(df, test_size=0.1)\n",
    "    train_equations = train_df['Filename'].tolist()\n",
    "    test_equations = test_df['Filename'].tolist()\n",
    "\n",
    "    input_test_df = input_df[input_df['Filename'].isin(test_equations)]\n",
    "    input_train_df = input_df[input_df['Filename'].isin(train_equations)]\n",
    "\n",
    "    input_train_df, input_val_df = train_test_split(input_train_df, test_size = 0.1, shuffle=True)\n",
    "\n",
    "    train_dataset = FeynmanDataset(input_train_df, dataset_dir)\n",
    "    val_dataset = FeynmanDataset(input_val_df, dataset_dir)\n",
    "    test_dataset = FeynmanDataset(input_test_df, dataset_dir)\n",
    "\n",
    "    datasets = {\n",
    "        \"train\":train_dataset,\n",
    "        \"test\":test_dataset,\n",
    "        \"valid\":val_dataset\n",
    "        }\n",
    "\n",
    "    return datasets\n",
    "\n",
    "def get_dataloaders(datasets, train_bs, test_bs):\n",
    "    train_dataloader = DataLoader(datasets['train'], batch_size=train_bs,\n",
    "                                  shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate_fn)\n",
    "    val_dataloader = DataLoader(datasets['valid'], batch_size=test_bs,\n",
    "                                  shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate_fn)\n",
    "    test_dataloader = DataLoader(datasets['test'], batch_size=test_bs,\n",
    "                                  shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate_fn)\n",
    "    \n",
    "    dataloaders = {\n",
    "        \"train\":train_dataloader,\n",
    "        \"test\":test_dataloader,\n",
    "        \"valid\":val_dataloader\n",
    "        }\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for (src_sample, tgt_sample) in batch:\n",
    "        src_batch.append(src_sample)\n",
    "        tgt_batch.append(tgt_sample)\n",
    "        \n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "253754cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:20.913253Z",
     "iopub.status.busy": "2024-03-30T06:34:20.912922Z",
     "iopub.status.idle": "2024-03-30T06:34:20.917956Z",
     "shell.execute_reply": "2024-03-30T06:34:20.917054Z"
    },
    "papermill": {
     "duration": 0.025084,
     "end_time": "2024-03-30T06:34:20.919810",
     "exception": false,
     "start_time": "2024-03-30T06:34:20.894726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    def __init__(self):\n",
    "        self.input_max_len = 100\n",
    "        self.df_path = '/kaggle/working/Modified.csv'\n",
    "        self.encoder_vocab = '/kaggle/input/gsoc-symba-task/encoder_vocab.txt'\n",
    "        self.decoder_vocab = '/kaggle/input/gsoc-symba-task/decoder_vocab.txt'\n",
    "        self.output_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cc46ab1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:20.954861Z",
     "iopub.status.busy": "2024-03-30T06:34:20.954509Z",
     "iopub.status.idle": "2024-03-30T06:34:21.017309Z",
     "shell.execute_reply": "2024-03-30T06:34:21.016486Z"
    },
    "papermill": {
     "duration": 0.082871,
     "end_time": "2024-03-30T06:34:21.019581",
     "exception": false,
     "start_time": "2024-03-30T06:34:20.936710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/gsoc-dataset-arrays/train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53573aec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.094316Z",
     "iopub.status.busy": "2024-03-30T06:34:21.093545Z",
     "iopub.status.idle": "2024-03-30T06:34:21.106670Z",
     "shell.execute_reply": "2024-03-30T06:34:21.105848Z"
    },
    "papermill": {
     "duration": 0.032333,
     "end_time": "2024-03-30T06:34:21.108735",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.076402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>data_num</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I.6.2a</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I.6.2a</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I.6.2a</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I.6.2a</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I.6.2a</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>III.21.20</td>\n",
       "      <td>995</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>III.21.20</td>\n",
       "      <td>996</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>III.21.20</td>\n",
       "      <td>997</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>III.21.20</td>\n",
       "      <td>998</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>III.21.20</td>\n",
       "      <td>999</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Filename  data_num  number\n",
       "0         I.6.2a         0     1.0\n",
       "1         I.6.2a         1     1.0\n",
       "2         I.6.2a         2     1.0\n",
       "3         I.6.2a         3     1.0\n",
       "4         I.6.2a         4     1.0\n",
       "...          ...       ...     ...\n",
       "99995  III.21.20       995   100.0\n",
       "99996  III.21.20       996   100.0\n",
       "99997  III.21.20       997   100.0\n",
       "99998  III.21.20       998   100.0\n",
       "99999  III.21.20       999   100.0\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e6cd4fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.183708Z",
     "iopub.status.busy": "2024-03-30T06:34:21.182861Z",
     "iopub.status.idle": "2024-03-30T06:34:21.404934Z",
     "shell.execute_reply": "2024-03-30T06:34:21.404136Z"
    },
    "papermill": {
     "duration": 0.241673,
     "end_time": "2024-03-30T06:34:21.407235",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.165562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = get_datasets(df_target,train_df,'/kaggle/input/gsoc-dataset-arrays/dataset_arrays/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f554edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.442850Z",
     "iopub.status.busy": "2024-03-30T06:34:21.442218Z",
     "iopub.status.idle": "2024-03-30T06:34:21.446993Z",
     "shell.execute_reply": "2024-03-30T06:34:21.446049Z"
    },
    "papermill": {
     "duration": 0.024589,
     "end_time": "2024-03-30T06:34:21.448882",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.424293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloaders = get_dataloaders(datasets,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78d5e832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.483456Z",
     "iopub.status.busy": "2024-03-30T06:34:21.483136Z",
     "iopub.status.idle": "2024-03-30T06:34:21.496203Z",
     "shell.execute_reply": "2024-03-30T06:34:21.495271Z"
    },
    "papermill": {
     "duration": 0.03261,
     "end_time": "2024-03-30T06:34:21.498178",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.465568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def generate_square_subsequent_mask(sz, device):\n",
    "#     mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "#     mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    mask = torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1).to(device)\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt, device):\n",
    "    src_seq_len = src.shape[1]\n",
    "    tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (torch.zeros((src.shape[0], src_seq_len), device=device)).type(torch.bool)\n",
    "#     src_padding_mask = (src == PAD_IDX)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX)\n",
    "    tgt_mask = tgt_mask\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "def sequence_accuracy(y_pred, y_true):\n",
    "    y_pred = list(y_pred)\n",
    "    y_true = list(y_true)\n",
    "    count = 0\n",
    "    total = len(y_pred)\n",
    "    for (predicted_tokens, original_tokens) in zip(y_pred, y_true):\n",
    "        original_tokens = original_tokens.tolist()\n",
    "        predicted_tokens = predicted_tokens.tolist()\n",
    "        if original_tokens == predicted_tokens:\n",
    "            count = count+1\n",
    "\n",
    "    return count/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f2ff4d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.533512Z",
     "iopub.status.busy": "2024-03-30T06:34:21.532686Z",
     "iopub.status.idle": "2024-03-30T06:34:21.548189Z",
     "shell.execute_reply": "2024-03-30T06:34:21.547290Z"
    },
    "papermill": {
     "duration": 0.035099,
     "end_time": "2024-03-30T06:34:21.550129",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.515030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    ''' helper Module to convert tensor of input indices into corresponding tensor of token embeddings'''\n",
    "    \n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    ''' helper Module that adds positional encoding to the token embedding to introduce a notion of word order.'''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        self.pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        self.pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        self.pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        self.pos_embedding = self.pos_embedding.unsqueeze(0)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding_1', self.pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "#         print(token_embedding.shape)\n",
    "        token_embedding = token_embedding.to('cuda:0')\n",
    "        self.pos_embedding = self.pos_embedding.to('cuda:0')\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:, :token_embedding.size(1), :])\n",
    "\n",
    "    \n",
    "class LinearPointEmbedder(nn.Module):\n",
    "    def __init__(self, vocab_size: int, input_emb_size, emb_size, max_input_points,dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, input_emb_size)\n",
    "        self.emb_size = emb_size\n",
    "        self.input_size = max_input_points*input_emb_size\n",
    "        self.fc1 = nn.Linear(self.input_size, emb_size)\n",
    "        self.fc2 = nn.Linear(emb_size, emb_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        out = self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "        bs, n = out.shape[0], out.shape[1]\n",
    "        out = out.view(bs, n, -1)\n",
    "        out = self.activation(self.fc1(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4692025a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.585116Z",
     "iopub.status.busy": "2024-03-30T06:34:21.584756Z",
     "iopub.status.idle": "2024-03-30T06:34:21.589332Z",
     "shell.execute_reply": "2024-03-30T06:34:21.588479Z"
    },
    "papermill": {
     "duration": 0.024281,
     "end_time": "2024-03-30T06:34:21.591309",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.567028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d5383a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.626178Z",
     "iopub.status.busy": "2024-03-30T06:34:21.625398Z",
     "iopub.status.idle": "2024-03-30T06:34:21.629592Z",
     "shell.execute_reply": "2024-03-30T06:34:21.628748Z"
    },
    "papermill": {
     "duration": 0.023621,
     "end_time": "2024-03-30T06:34:21.631437",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.607816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PAD_INDEX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "008ad167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.668054Z",
     "iopub.status.busy": "2024-03-30T06:34:21.667702Z",
     "iopub.status.idle": "2024-03-30T06:34:21.717166Z",
     "shell.execute_reply": "2024-03-30T06:34:21.716095Z"
    },
    "papermill": {
     "duration": 0.071378,
     "end_time": "2024-03-30T06:34:21.719507",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.648129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#GLU\n",
    "class GatedConvolution(nn.Module):\n",
    "    def __init__(self, hidden_dim, kernel_size=3, padding=1):\n",
    "        super(GatedConvolution,self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=hidden_dim, \n",
    "            out_channels=hidden_dim * 2,\n",
    "            kernel_size=kernel_size, \n",
    "            padding=padding, bias=True\n",
    "        )\n",
    "\n",
    "        init.xavier_uniform_(self.conv.weight, gain=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        convoluted = self.conv(x.transpose(1,2)).transpose(1,2)\n",
    "        out, gate = convoluted.split(int(convoluted.size(-1) / 2), -1)\n",
    "        out = out * torch.sigmoid(gate)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SeparableConv1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(SeparableConv1D, self).__init__()\n",
    "\n",
    "        self.depth_wise = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"same\",\n",
    "            groups=in_channels\n",
    "        )\n",
    "        \n",
    "        self.point_wise = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depth_wise(x)\n",
    "        out = self.point_wise(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class EncoderCell(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(EncoderCell, self).__init__()\n",
    "\n",
    "        self.pad_id = 0 #config.pad_id\n",
    "        self.glu = GatedConvolution(config.hidden_dim)\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            config.hidden_dim, config.nhead, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.mid_layer_norm = nn.LayerNorm(config.pff_dim)\n",
    "        self.layer_norms = clones(nn.LayerNorm(config.hidden_dim), 4)\n",
    "\n",
    "        self.left_net = nn.Sequential(\n",
    "            nn.Linear(config.hidden_dim, config.pff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout)\n",
    "        )\n",
    "\n",
    "        self.right_net = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=config.hidden_dim, \n",
    "                      out_channels=config.hidden_dim//2, \n",
    "                      kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout)\n",
    "        )\n",
    "\n",
    "        self.sep_conv = SeparableConv1D(\n",
    "            config.pff_dim, config.hidden_dim // 2, 9\n",
    "        )\n",
    "\n",
    "        self.pff = nn.Sequential(\n",
    "            nn.Linear(config.hidden_dim, config.pff_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(config.pff_dim, config.hidden_dim)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, e_mask):\n",
    "        ### Block_01\n",
    "        B01_out = self.glu(self.layer_norms[0](x)) #Dim:512\n",
    "\n",
    "\n",
    "        ### Block_02\n",
    "        B02_normed = self.layer_norms[1](B01_out)        \n",
    "\n",
    "        left_out = self.left_net(B02_normed)\n",
    "        right_out = self.right_net(B02_normed.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "        right_out = F.pad(\n",
    "            input=right_out, \n",
    "            pad=(0, left_out.size(-1) - right_out.size(-1), 0,0,0,0), \n",
    "            mode='constant', value= self.pad_id\n",
    "        ) #Dim:2048          \n",
    "\n",
    "        B02_out = left_out + right_out\n",
    "\n",
    "\n",
    "        ### Block_03\n",
    "        B03_out = self.mid_layer_norm(B02_out)\n",
    "        \n",
    "        B03_out = self.sep_conv(\n",
    "            B03_out.transpose(1, 2)\n",
    "        ).transpose(1, 2) #Dim:256\n",
    "        \n",
    "        B03_out = F.pad(\n",
    "            input=B03_out,\n",
    "            pad=(0, B01_out.size(-1) - B03_out.size(-1), 0, 0, 0, 0),\n",
    "            mode='constant', value= self.pad_id\n",
    "        )\n",
    "        \n",
    "        B03_out += B01_out #Dim:512\n",
    "\n",
    "\n",
    "        ### Block_04\n",
    "        B04_out = self.layer_norms[2](B03_out)\n",
    "        \n",
    "        attention_out = self.attention(\n",
    "            B04_out, B04_out, B04_out,\n",
    "            key_padding_mask = e_mask,\n",
    "            need_weights=False\n",
    "        )[0]\n",
    "        \n",
    "        B04_out += attention_out #Dim:512\n",
    "\n",
    "\n",
    "        ### Block_05 & 06\n",
    "        out = self.layer_norms[3](B04_out)\n",
    "        out = self.pff(out) + B04_out #Dim:512\n",
    "        return out \n",
    "\n",
    "\n",
    "class DecoderCell(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(DecoderCell, self).__init__()\n",
    "        \n",
    "        self.pad_id = 0 #config.pad_id\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            config.hidden_dim, config.nhead\n",
    "        )\n",
    "\n",
    "        self.mid_layer_norm = nn.LayerNorm(config.hidden_dim * 2)\n",
    "        \n",
    "        self.layer_norms = clones(nn.LayerNorm(config.hidden_dim), 5)\n",
    "\n",
    "        self.left_attn = nn.MultiheadAttention(\n",
    "            config.hidden_dim, config.nhead * 2, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.right_attn = nn.MultiheadAttention(\n",
    "            config.hidden_dim, config.nhead, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.left_net = nn.Sequential(\n",
    "            SeparableConv1D(config.hidden_dim, config.hidden_dim * 2, 11), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.right_net = SeparableConv1D(\n",
    "            config.hidden_dim, config.hidden_dim // 2, 7\n",
    "        )\n",
    "        \n",
    "        self.sep_conv = SeparableConv1D(\n",
    "            config.hidden_dim * 2, config.hidden_dim, 7\n",
    "        )\n",
    "\n",
    "\n",
    "        self.self_attn = nn.MultiheadAttention(\n",
    "            config.hidden_dim, config.nhead * 2, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.src_attn = nn.MultiheadAttention(\n",
    "            config.hidden_dim, config.nhead, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.pff = nn.Sequential(\n",
    "            nn.Linear(config.hidden_dim, config.pff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config.pff_dim, config.hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, memory, e_mask, d_mask):\n",
    "\n",
    "        ### Block_01\n",
    "        B01_out = self.layer_norms[0](x)\n",
    "\n",
    "        left_out = self.left_attn(\n",
    "            B01_out, B01_out, B01_out,\n",
    "            attn_mask=d_mask,\n",
    "            need_weights=False\n",
    "        )[0]\n",
    "\n",
    "        right_out = self.right_attn(\n",
    "            B01_out, B01_out, B01_out,\n",
    "            attn_mask=d_mask,\n",
    "            need_weights=False\n",
    "        )[0]\n",
    "\n",
    "        B01_out = left_out + right_out\n",
    "\n",
    "\n",
    "        ### Block_02\n",
    "        B02_out = self.layer_norms[1](B01_out)\n",
    "        left_out = self.left_net(B02_out.transpose(1, 2)).transpose(1, 2)\n",
    "        right_out = self.right_net(B02_out.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "        right_out = F.pad(\n",
    "            input=right_out, \n",
    "            pad=(0, left_out.size(-1) - right_out.size(-1), 0,0,0,0), \n",
    "            mode='constant', value= self.pad_id\n",
    "        ) #Dim:1024\n",
    "                             \n",
    "        B02_out = left_out + right_out #Dim: 1024\n",
    "\n",
    "        ### Block_03\n",
    "        B03_out = self.mid_layer_norm(B02_out)\n",
    "        B03_out = self.sep_conv(B03_out.transpose(1, 2)).transpose(1, 2)\n",
    "        B03_out += B01_out\n",
    "\n",
    "\n",
    "        ### Block_04\n",
    "        B04_out = self.layer_norms[2](B03_out)\n",
    "        \n",
    "        B04_out = self.self_attn(\n",
    "            B04_out, B04_out, B04_out,\n",
    "            attn_mask=d_mask,\n",
    "            need_weights=False\n",
    "        )[0]\n",
    "\n",
    "        B04_out += B03_out\n",
    "\n",
    "\n",
    "        ### Block_05\n",
    "        B05_out = self.layer_norms[3](B04_out)\n",
    "        \n",
    "        B05_out = self.src_attn(\n",
    "            B05_out, memory, memory,\n",
    "            key_padding_mask=e_mask,\n",
    "            need_weights=False\n",
    "        )[0]\n",
    "\n",
    "        B05_out += B04_out        \n",
    "\n",
    "\n",
    "        ### Block_06 & Block_07\n",
    "        out = self.layer_norms[4](B05_out)\n",
    "        out = self.pff(out) + B05_out #Dim:512\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class EvolvedEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(EvolvedEncoder, self).__init__()\n",
    "        \n",
    "        self.embeddings = LinearPointEmbedder(config.src_vocab_size, config.input_emb_size, config.embedding_size, config.max_input_points, config.dropout)\n",
    "        self.positional_encoding = PositionalEncoding(config.embedding_size, config.dropout)\n",
    "        self.cells = clones(EncoderCell(config), config.num_encoder_layers)\n",
    "\n",
    "\n",
    "    def forward(self, x, e_mask):\n",
    "        x = self.embeddings(x)\n",
    "#         x = self.positional_encoding(x)\n",
    "        for cell in self.cells:\n",
    "            x = cell(x, e_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EvolvedDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(EvolvedDecoder, self).__init__()\n",
    "\n",
    "        self.embeddings = TokenEmbedding(config.tgt_vocab_size, config.embedding_size)\n",
    "        self.positional_encoding = PositionalEncoding(config.embedding_size, config.dropout)\n",
    "        self.cells = clones(DecoderCell(config), config.num_decoder_layers)\n",
    "\n",
    "\n",
    "    def forward(self, x, memory, e_mask, d_mask):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        for cell in self.cells:\n",
    "            x = cell(x, memory, e_mask, d_mask)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class EvolvedTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(EvolvedTransformer, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.pad_id = 0 #config.pad_id\n",
    "        self.device = config.device\n",
    "        self.src_vocab_size = config.src_vocab_size\n",
    "        self.tgt_vocab_size = config.tgt_vocab_size\n",
    "        \n",
    "\n",
    "        self.encoder = EvolvedEncoder(config) \n",
    "        \n",
    "        self.decoder = EvolvedDecoder(config)\n",
    "        \n",
    "        self.generator = nn.Linear(config.hidden_dim, config.tgt_vocab_size)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def dec_mask(self, x):\n",
    "        sz = x.size(1)\n",
    "        return torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1).to(self.device)\n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        e_mask = (torch.zeros((x.shape[0], x.shape[1]), device=self.device)).type(torch.bool)\n",
    "        d_mask = self.dec_mask(y)\n",
    "\n",
    "        memory = self.encoder(x, e_mask)\n",
    "        dec_out = self.decoder(y, memory, e_mask, d_mask)\n",
    "\n",
    "        logit = self.generator(dec_out)\n",
    "\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1653e4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.756218Z",
     "iopub.status.busy": "2024-03-30T06:34:21.755855Z",
     "iopub.status.idle": "2024-03-30T06:34:21.803718Z",
     "shell.execute_reply": "2024-03-30T06:34:21.802744Z"
    },
    "papermill": {
     "duration": 0.068683,
     "end_time": "2024-03-30T06:34:21.805778",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.737095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Trainer class for training and evaluating a PyTorch model.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, dataloaders):\n",
    "        \"\"\"\n",
    "        Initialize Trainer object.\n",
    "\n",
    "        Args:\n",
    "        - config: Configuration object containing training parameters\n",
    "        - dataloaders: Dictionary containing data loaders for train, validation, and test sets\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.device = torch.device(self.config.device)\n",
    "        self.dataloaders = dataloaders\n",
    "\n",
    "        seed_everything(self.config.seed)\n",
    "\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        if self.config.use_half_precision:\n",
    "            self.dtype = torch.float16\n",
    "        else:\n",
    "            self.dtype = torch.float32\n",
    "\n",
    "        # Initialize model, optimizer, scheduler, and criterion\n",
    "        self.model = self.get_model()\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = self.get_optimizer()\n",
    "        self.scheduler = self.get_scheduler()\n",
    "        self.criterion = self.get_criterion()\n",
    "\n",
    "        # Initialize training-related variables\n",
    "        self.current_epoch = 0\n",
    "        self.best_accuracy = -1\n",
    "        self.best_val_loss = 1e6\n",
    "        self.train_loss_list = []\n",
    "        self.valid_loss_list = []\n",
    "        self.valid_accuracy_tok_list = []\n",
    "\n",
    "        # Create directory for saving logs\n",
    "        self.logs_dir = os.path.join(self.config.root_dir, self.config.experiment_name)\n",
    "        os.makedirs(self.logs_dir, exist_ok=True)\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        Initialize and return the model based on the configuration.\n",
    "        \"\"\"\n",
    "        model = EvolvedTransformer(num_encoder_layers=self.config.num_encoder_layers,\n",
    "                    num_decoder_layers=self.config.num_decoder_layers,\n",
    "                    emb_size=self.config.embedding_size,\n",
    "                    nhead=self.config.nhead,\n",
    "                    src_vocab_size=self.config.src_vocab_size,\n",
    "                    tgt_vocab_size=self.config.tgt_vocab_size,\n",
    "                    input_emb_size=self.config.input_emb_size,\n",
    "                    max_input_points=self.config.max_input_points,\n",
    "                    )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        \"\"\"\n",
    "        Initialize and return the optimizer based on the configuration.\n",
    "        \"\"\"\n",
    "        optimizer_parameters = self.model.parameters()\n",
    "\n",
    "        if self.config.optimizer_type == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(optimizer_parameters, lr=self.config.optimizer_lr, momentum=self.config.optimizer_momentum,)\n",
    "        elif self.config.optimizer_type == \"adam\":\n",
    "            optimizer = torch.optim.Adam(optimizer_parameters, lr=self.config.optimizer_lr, eps=1e-8, weight_decay=self.config.optimizer_weight_decay)\n",
    "        elif self.config.optimizer_type == \"adamw\":\n",
    "            optimizer = torch.optim.AdamW(optimizer_parameters, lr=self.config.optimizer_lr, eps=1e-8, weight_decay=self.config.optimizer_weight_decay)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        return optimizer\n",
    "    \n",
    "    def get_scheduler(self):\n",
    "        \"\"\"\n",
    "        Initialize and return the learning rate scheduler based on the configuration.\n",
    "        \"\"\"\n",
    "        if self.config.scheduler_type == \"multi_step\":\n",
    "            scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=self.config.scheduler_milestones, gamma=self.config.scheduler_gamma)\n",
    "        elif self.config.scheduler_type == \"reduce_lr_on_plateau\":\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', patience=2)\n",
    "        elif self.config.scheduler_type == \"cosine_annealing_warm_restart\":\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.optimizer, self.config.T_0, self.config.T_mult)\n",
    "        elif self.config.scheduler_type == \"none\":\n",
    "            scheduler = None\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        return scheduler\n",
    "\n",
    "    \n",
    "    def get_criterion(self):\n",
    "        \"\"\"\n",
    "        Initialize and return the loss function based on the configuration.\n",
    "        \"\"\"\n",
    "        if self.config.criterion == \"cross_entropy\":\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        return criterion\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "        \"\"\"\n",
    "        Train the model for one epoch.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        pbar = tqdm(self.dataloaders['train'], total=len(self.dataloaders['train']))\n",
    "        pbar.set_description(f\"[{self.current_epoch+1}/{self.config.epochs}] Train\")\n",
    "        running_loss = AverageMeter()\n",
    "        for src, tgt in pbar:\n",
    "            src = src.to(self.device)\n",
    "            tgt = tgt.to(self.device)\n",
    "\n",
    "            bs = src.size(0)\n",
    "\n",
    "            with torch.autocast(device_type='cuda', dtype=self.dtype):\n",
    "                logits = self.model(src, tgt[:, :-1])\n",
    "                loss = self.criterion(logits.reshape(-1, logits.shape[-1]), tgt[:, 1:].reshape(-1))\n",
    "                \n",
    "            running_loss.update(loss.item(), bs)\n",
    "            pbar.set_postfix(loss=running_loss.avg)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            self.scaler.scale(loss).backward()\n",
    "\n",
    "            if self.config.clip_grad_norm > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.clip_grad_norm)\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "\n",
    "        return running_loss.avg\n",
    "\n",
    "    def evaluate(self, phase):\n",
    "        \"\"\"\n",
    "        Evaluate the model on validation or test data.\n",
    "\n",
    "        Args:\n",
    "        - phase: Phase of evaluation, either \"valid\" or \"test\".\n",
    "\n",
    "        Returns:\n",
    "        - Tuple containing average token accuracy and average loss.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        pbar = tqdm(self.dataloaders[phase], total=len(self.dataloaders[phase]))\n",
    "        pbar.set_description(f\"[{self.current_epoch+1}/{self.config.epochs}] {phase.capitalize()}\")\n",
    "        running_loss = AverageMeter()\n",
    "        running_acc_tok = AverageMeter()\n",
    "        \n",
    "        \n",
    "        for src, tgt in pbar:\n",
    "            src = src.to(self.device)\n",
    "            tgt = tgt.to(self.device)\n",
    "            bs = src.size(0)\n",
    "            \n",
    "            with torch.autocast(device_type='cuda', dtype=self.dtype):\n",
    "                with torch.no_grad():\n",
    "                    logits = self.model(src, tgt[:, :-1])\n",
    "                    loss = self.criterion(logits.reshape(-1, logits.shape[-1]), tgt[:, 1:].reshape(-1))\n",
    "\n",
    "            y_pred = torch.argmax(logits.reshape(-1, logits.shape[-1]), 1)\n",
    "            correct = (y_pred == tgt[:, 1:].reshape(-1)).cpu().numpy().mean()\n",
    "            \n",
    "            running_loss.update(loss.item(), bs)\n",
    "            running_acc_tok.update(correct, bs)\n",
    "            \n",
    "        return running_acc_tok.avg, running_loss.avg\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Main training loop.\n",
    "        \"\"\"\n",
    "        start_epoch = self.current_epoch\n",
    "        for self.current_epoch in range(start_epoch, self.config.epochs):\n",
    "            training_loss = self.train_one_epoch() \n",
    "            valid_accuracy_tok, valid_loss = self.evaluate(\"valid\")\n",
    "            \n",
    "            self.train_loss_list.append(round(training_loss, 7))\n",
    "            self.valid_loss_list.append(round(valid_loss, 7))\n",
    "            self.valid_accuracy_tok_list.append(round(valid_accuracy_tok, 7))\n",
    "            \n",
    "            if self.scheduler == \"multi_step\":\n",
    "                self.scheduler.step()\n",
    "            elif self.scheduler == \"reduce_lr_on_plateau\":\n",
    "                self.scheduler.step(valid_loss)\n",
    "                \n",
    "            if valid_loss<self.best_val_loss:\n",
    "                self.best_val_loss = valid_loss\n",
    "\n",
    "            self.save_model(\"last_checkpoint.pth\")\n",
    "\n",
    "            if valid_accuracy_tok > self.best_accuracy:\n",
    "                print(f\"==> Best Accuracy improved to {round(valid_accuracy_tok, 7)} from {self.best_accuracy}\")\n",
    "                self.best_accuracy = round(valid_accuracy_tok, 7)\n",
    "                self.save_model(\"best_checkpoint.pth\")\n",
    "            \n",
    "            self.log_results()\n",
    "\n",
    "        \n",
    "    def save_model(self, file_name):\n",
    "        \"\"\"\n",
    "        Save model checkpoints.\n",
    "        \"\"\"\n",
    "        state_dict = self.model.state_dict()\n",
    "        torch.save({\n",
    "                \"epoch\": self.current_epoch + 1,\n",
    "                \"state_dict\": state_dict,\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "                \"train_loss_list\": self.train_loss_list,\n",
    "                \"valid_loss_list\": self.valid_loss_list,\n",
    "                \"valid_accuracy_tok_list\": self.valid_accuracy_tok_list,\n",
    "            }, os.path.join(self.logs_dir, file_name))\n",
    "\n",
    "    def log_results(self):\n",
    "        \"\"\"\n",
    "        Log training results to a CSV file.\n",
    "        \"\"\"\n",
    "        data_list = [self.train_loss_list, self.valid_loss_list, self.valid_accuracy_tok_list]\n",
    "        column_list = ['train_losses', 'valid_losses', 'token_valid_accuracy']\n",
    "        \n",
    "        df_data = np.array(data_list).T\n",
    "        df = pd.DataFrame(df_data, columns=column_list)\n",
    "        df.to_csv(os.path.join(self.logs_dir, \"logs.csv\"))\n",
    "        \n",
    "    def test_seq_acc(self):\n",
    "        \"\"\"\n",
    "        Evaluate model's sequence accuracy on test data.\n",
    "        \"\"\"\n",
    "        file = os.path.join(self.logs_dir, \"best_checkpoint.pth\")\n",
    "        state_dict = torch.load(file, map_location=self.device)['state_dict']\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        \n",
    "        test_accuracy_tok, _ = self.evaluate(\"test\")\n",
    "        \n",
    "        predictor = Predictor(self.config)\n",
    "        \n",
    "        pbar = tqdm(self.dataloaders[\"test\"], total=len(self.dataloaders[\"test\"]))\n",
    "        pbar.set_description(f\"Test\")\n",
    "        \n",
    "        y_preds = []\n",
    "        y_true = []\n",
    "        for src, tgt in pbar:\n",
    "            src = src.to(self.device)\n",
    "            tgt = tgt.numpy()\n",
    "            bs = src.size(0)\n",
    "            for i in range(0,bs):\n",
    "                y_pred = predictor.predict(src[i].unsqueeze(0))\n",
    "                y_preds.append(y_pred.cpu().numpy())\n",
    "                y_true.append(np.trim_zeros(tgt[i]))\n",
    "\n",
    "        test_accuracy_seq = sequence_accuracy(y_true, y_preds)\n",
    "        f= open(os.path.join(self.logs_dir, \"score.txt\"),\"w+\")\n",
    "        f.write(f\"Token Accuracy = {(round(test_accuracy_tok, 7))}\\n\")\n",
    "        f.write(f\"Sequence Accuracy = {(round(test_accuracy_seq, 7))}\\n\")\n",
    "        f.close()\n",
    "        print(f\"Test Accuracy: {round(test_accuracy_tok, 7)} | Valid Accuracy: {self.best_accuracy}\") \n",
    "        print(f\"Test Sequence Accuracy: {test_accuracy_seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79d861",
   "metadata": {
    "papermill": {
     "duration": 0.016353,
     "end_time": "2024-03-30T06:34:21.840136",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.823783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae2d08ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.875684Z",
     "iopub.status.busy": "2024-03-30T06:34:21.874822Z",
     "iopub.status.idle": "2024-03-30T06:34:21.897815Z",
     "shell.execute_reply": "2024-03-30T06:34:21.896824Z"
    },
    "papermill": {
     "duration": 0.043195,
     "end_time": "2024-03-30T06:34:21.899894",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.856699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BOS_IDX = 1\n",
    "EOS_IDX = 2\n",
    "\n",
    "class Predictor:\n",
    "    \"\"\"\n",
    "    Predictor class for generating predictions using a trained model.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initialize Predictor object.\n",
    "\n",
    "        Args:\n",
    "        - config: Configuration object containing model parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.device = torch.device(self.config.device)\n",
    "\n",
    "        # Get the model\n",
    "        self.model = self.get_model()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # Load the best checkpoint\n",
    "        self.logs_dir = os.path.join(self.config.root_dir, self.config.experiment_name)\n",
    "        path = os.path.join(self.logs_dir, \"best_checkpoint.pth\")\n",
    "        self.model.load_state_dict(torch.load(path)[\"state_dict\"])\n",
    "        \n",
    "        # Set the model to evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "    def get_model(self):\n",
    "        model = EvolvedTransformer(num_encoder_layers=self.config.num_encoder_layers,\n",
    "                      num_decoder_layers=self.config.num_decoder_layers,\n",
    "                      emb_size=self.config.embedding_size,\n",
    "                      nhead=self.config.nhead,\n",
    "                      src_vocab_size=self.config.src_vocab_size,\n",
    "                      tgt_vocab_size=self.config.tgt_vocab_size,\n",
    "                      input_emb_size=self.config.input_emb_size,\n",
    "                      max_input_points=self.config.max_input_points,\n",
    "                      )\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.model.eval()\n",
    "        ys = torch.ones(1, 1).fill_(BOS_IDX).type(torch.long).to(self.device)\n",
    "        e_mask = torch.zeros(1, x.shape[1]).type(torch.bool).to(self.device)\n",
    "        memory = self.model.encoder(x, e_mask)\n",
    "\n",
    "        for idx in range(1, 256):\n",
    "            d_mask = torch.triu(torch.full((ys.size(1), ys.size(1)), float('-inf')), diagonal=1).to(self.device)\n",
    "            d_out = self.model.decoder(ys, memory, e_mask, d_mask)\n",
    "\n",
    "            prob = self.model.generator(d_out[:, -1])\n",
    "            _, next_word = torch.max(prob, dim=1)\n",
    "            next_word = next_word.item()\n",
    "            ys = torch.cat([ys, torch.ones(1, 1).type_as(x.data).fill_(next_word)], dim=1)\n",
    "            if next_word == EOS_IDX:\n",
    "                break\n",
    "\n",
    "        return ys.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5eadd368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.936446Z",
     "iopub.status.busy": "2024-03-30T06:34:21.936069Z",
     "iopub.status.idle": "2024-03-30T06:34:21.951235Z",
     "shell.execute_reply": "2024-03-30T06:34:21.950302Z"
    },
    "papermill": {
     "duration": 0.036401,
     "end_time": "2024-03-30T06:34:21.953367",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.916966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    experiment_name: Optional[str] = \"evolved_transformer\"\n",
    "    root_dir: Optional[str] = \"./\"\n",
    "    device: Optional[str] = \"cuda:0\"\n",
    "        \n",
    "    #training parameters\n",
    "    epochs: Optional[int] = 4\n",
    "    seed: Optional[int] = 42\n",
    "    use_half_precision: Optional[bool] = True\n",
    "\n",
    "    # scheduler parameters\n",
    "    scheduler_type: Optional[str] = \"multi_step\" # multi_step or none\n",
    "    scheduler_gamma: Optional[float] = 0.1\n",
    "    scheduler_milestones: Optional[list] = [5, 10, 15]\n",
    "\n",
    "    # optimizer parameters\n",
    "    optimizer_type: Optional[str] = \"adamw\" # sgd or adam\n",
    "    optimizer_lr: Optional[float] = 0.0003   \n",
    "    optimizer_momentum: Optional[float] = 0.9\n",
    "    optimizer_weight_decay: Optional[float] = 0.0\n",
    "    optimizer_no_decay: Optional[list] = field(default_factory=list)\n",
    "    clip_grad_norm: Optional[float] = -1\n",
    "        \n",
    "    # Model Parameters\n",
    "    embedding_size: Optional[int] = 512\n",
    "    hidden_dim: Optional[int] = 512\n",
    "    nhead: Optional[int] = 8\n",
    "    num_encoder_layers: Optional[int] = 2\n",
    "    num_decoder_layers: Optional[int] = 4\n",
    "    dropout: Optional[int] = 0.1\n",
    "    pff_dim = 128\n",
    "    pretrain: Optional[bool] = False\n",
    "    input_emb_size: Optional[int] = 256\n",
    "    max_input_points: Optional[int] = 30\n",
    "    src_vocab_size: Optional[int] = 1204\n",
    "    tgt_vocab_size: Optional[int] = 37\n",
    "    hybrid = True\n",
    "\n",
    "    # Criterion\n",
    "    criterion: Optional[str] = \"cross_entropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb328fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:21.990946Z",
     "iopub.status.busy": "2024-03-30T06:34:21.990569Z",
     "iopub.status.idle": "2024-03-30T06:34:21.994796Z",
     "shell.execute_reply": "2024-03-30T06:34:21.993957Z"
    },
    "papermill": {
     "duration": 0.024807,
     "end_time": "2024-03-30T06:34:21.996732",
     "exception": false,
     "start_time": "2024-03-30T06:34:21.971925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2be085a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:22.031890Z",
     "iopub.status.busy": "2024-03-30T06:34:22.031549Z",
     "iopub.status.idle": "2024-03-30T06:34:22.036006Z",
     "shell.execute_reply": "2024-03-30T06:34:22.035073Z"
    },
    "papermill": {
     "duration": 0.024043,
     "end_time": "2024-03-30T06:34:22.037969",
     "exception": false,
     "start_time": "2024-03-30T06:34:22.013926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d1a8edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:34:22.240902Z",
     "iopub.status.busy": "2024-03-30T06:34:22.240527Z",
     "iopub.status.idle": "2024-03-30T08:34:14.756256Z",
     "shell.execute_reply": "2024-03-30T08:34:14.754476Z"
    },
    "papermill": {
     "duration": 7192.535714,
     "end_time": "2024-03-30T08:34:14.758318",
     "exception": true,
     "start_time": "2024-03-30T06:34:22.222604",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/4] Train: 100%|██████████| 1266/1266 [28:59<00:00,  1.37s/it, loss=0.639]\n",
      "[1/4] Valid: 100%|██████████| 141/141 [00:59<00:00,  2.38it/s]\n",
      "==> Best Accuracy improved to 0.9748144 from -1\n",
      "[2/4] Train: 100%|██████████| 1266/1266 [28:27<00:00,  1.35s/it, loss=0.0458]\n",
      "[2/4] Valid: 100%|██████████| 141/141 [00:58<00:00,  2.41it/s]\n",
      "==> Best Accuracy improved to 0.9917946 from 0.9748144\n",
      "[3/4] Train: 100%|██████████| 1266/1266 [28:29<00:00,  1.35s/it, loss=0.0212]\n",
      "[3/4] Valid: 100%|██████████| 141/141 [00:58<00:00,  2.41it/s]\n",
      "==> Best Accuracy improved to 0.9937256 from 0.9917946\n",
      "[4/4] Train: 100%|██████████| 1266/1266 [28:29<00:00,  1.35s/it, loss=0.0158]\n",
      "[4/4] Valid: 100%|██████████| 141/141 [00:58<00:00,  2.40it/s]\n",
      "==> Best Accuracy improved to 0.9963348 from 0.9937256\n",
      "[4/4] Test: 100%|██████████| 157/157 [01:05<00:00, 2.41it/s]\n",
      "Test: 100%|██████████| 157/157 [00:32<00:00,  4.71it/s]\n",
      "Test Accuracy: 0.8568555 | Valid Accuracy: 0.9963348\n",
      "Test Sequence Accuracy: 0.223\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config,dataloaders)\n",
    "trainer.train()\n",
    "trainer.test_seq_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e0588a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268382de",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655bbcd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a09c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2659f8c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908396e3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4660212,
     "sourceId": 7928956,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4668824,
     "sourceId": 7963244,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4610731,
     "isSourceIdPinned": false,
     "sourceId": 7975185,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4655603,
     "sourceId": 7977557,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7211.078295,
   "end_time": "2024-03-30T08:34:18.573785",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-30T06:34:07.495490",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
